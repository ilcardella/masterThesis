\chapter{Introduction}
\label{cap1}

Autonomous drones are performing a revolution in the field of mobile sensing: various type of drones are used to perform a great number of applications, since they can carry rich sensor payloads, such as cameras and instruments.
Often there is a simple abstraction which allows drones navigation: they can be controlled through mobile devices or by setting waypoints from a desktop application.
The great deal with drones is that they can greatly extend the capabilities of traditional sensing systems while simultaneously reducing cost.
\\

Many drones applications have been developed in the recent years, performing a wide range of different functionality, but they are all suitable for outdoor contexts.
We aim to create a new programming model for the collaboration of nano-drones, in order to extend the support for the developers who want to create new applications in indoor contexts.
\\

The indoor context implies applications with different requirements compared to the outdoor ones:
there is need for a small number of drones(5/10), each one performing a different action independently from the others, while in the outdoor environment generally there is need for a large number of drones to perform the same action.
We formalize this problem with the concept of \textit{Trip}, that is nothing but a movement of a drone from a point A to a point B at the end of which an action (picture,measurement etc.) is performed.
Existing frameworks do not allow the developer to deal with the concept of Trip.
We also want to make our framework autonomous while choosing which drone has to physically carry out the Trip.
\\

From a technological point of view, GPS cannot be used in indoor contexts.
Furthermore, the indoor context implies moving in small areas which are usually full of people and obstacles, so the drones have to be small, in order to avoid crashes with both human and environmental obstacles.
Size limitations result in other problems such as the low battery duration and the maximum transportable weight.
So, we need to give a contribution to the actual state of the art in order to derive a new programming system crossing all the previous requirements.
Our programming framework has an architecture in which the central brain is independent from the particular navigation API, which means that the system manages the dispatching of drones and their failures independently of the specific navigation algorithm.


\section{Contribution}

Imagine a medical context where the nurses' duty is to deliver, every day at the same hour, the patients' daily medicines.
A drone could achieve this task flying room by room and leaving the pills to the relative patient's desk. 
It would be way better if a group of drones could manage these tasks simultaneously.
\\

In order to create an application able to carry out this task, a developer could program each drone individually, making use of a specific API to command them, and taking care of the complex duty of managing the coordination between them. 
Our goal is to build a more clever programming framework, where a central brain manages the dispatching of the drones simultaneously and expresses how the drones should behave to accomplish these tasks, managing also the failures due to crashes of the drones and batteries getting empty. 
Chapter \ref{cap2} illustrates in details the possible ways to achieve this goal:
instead of using a \textit{Drone Oriented} approach, the developer could use either a \textit{Swam Oriented} or a \textit{Team Level} approach. 
There are several available frameworks such as Karma\cite{karma} and Voltron\cite{voltron}, but no one of them is fully suitable for our programming model, shown in section \ref{programmingModel}.
\\

As already said, we deal with the indoor context, that implies applications with different requirements compared to the outdoor ones:
there is need for a small number of drones(5/10), each one performing a different action independently from the others, while in the outdoor environment generally there is need for a large number of drones to perform the same action.
We formalize this problem with the concept of \textit{Trip}, that is nothing but a movement of a drone from a point A to a point B at the end of which an action (picture,measurement etc.) is performed. 
No other framework allows the user to define the idea of a Trip as a movement from point A to point B to accomplish an action.
Another fundamental feature of our framework is that the central brain takes care of the important decision to choose which drone to assign to a given Trip, facilitating the work of the programmer in the development of his application.
As said, the system manages the failed trips in the same way.
For example, when a drone crashes, the system chooses a new drone to complete the interrupted Trip, without any intervention of the programmer and the final user.
\\

We wanted to facilitate as much as possible the work of the programmer, so we decided to create the Graphical Editor, fully described in Section \ref{plutoGraphicalEditor}.
Thanks to this editor, the programmer can develop its application by drawing functional blocks and then connecting them with arrows.
Each block represents a feature: there is a block that assigns a Drone to a Trip, one that sends the drones to the target location, etc.
The developer can connect the blocks needed according to the requirements of the specific application.
From the drawn graph the programmer can generate the source code of the Main Application mentioned before. This source code is dependent on the graph and adds to the Main Application all the features expressed by the chosen blocks.
\\

In order to define the sensing tasks, we developed the Pluto Main Application, that is the final user interface fully described in Section \ref{plutoMainApp}.
It allows the final user to choose the actions to perform and where they must be performed, by simply dragging and dropping the actions on a map. 
An Action could be the taking of a photo, a measurement of some parameters or a custom task expressed by the developer.
\\

Finally we evaluated the Pluto framework under different points of view, as described in Chapter \ref{cap6}. 
First of all, we chose some already existing applications and tried to develop them from scratch with Pluto.
Then we evaluated the framework usability, proposing some exercises to real testers and asking them for a feedback through a survey.
Finally we focused our attention on the software and hardware metrics such as the code complexity and the CPU consumption. 
We defined some metrics to evaluate both the users' exercises and the software and hardware metrics.
After a detailed analysis of both the metrics results and the answers to the user survey,
the results convinced us about Pluto capability to simplify the duties of a developer in implementing a drone application.
The whole evaluation process is shown in Chapter \ref{cap6}


\section{Outline}

In this Chapter, we have given the general context and the general goals of the work together with a brief description of our work.
\\

In Chapter~\ref{cap2} there is a description of the actual state of the art in the context of our work.
In Sections \ref{droneLevel}, \ref{swarmLevel} and \ref{teamlevel} we describe the three main existing approaches for drone programming, the "Swarm-level","Drone-level" and "Team-level" respectively, also proposing existing examples for each one of them.
We show that no one of these approaches is suitable for our requirements, since we need the concepts of missions and trips.
A mission is a list of sensing tasks to be performed sequentially and a trip is a movement from a point A to a point B in the environment to perform an action.
Then, in Section \ref{dataflow}, we describe the dataflow programming method, that we adopted for the Pluto Graphical Editor, providing two existing examples of it.
Also in this case, we show that we need a different approach, since we need to use only a group of basic components for our work, while the existing solutions are too general and include a lot of complex components.
\\

Chapter~\ref{cap3} is focused on the problems stemming from the indoor context and on the requirements deriving from it.
In Section \ref{motivating}, we show a motivating example application, in order to better explain the requirements and problems deriving from our work.
In Section \ref{teamlevelproblems} we show the implementation problems deriving from using a Team-level approach for our system, also proposing the solutions to fix them.
Finally, in Section \ref{challenges} we show the technological limitations affecting our system, such as the indoor localization and nano-drone batteries problems.
\\

Chapter~\ref{cap4} presents our solution for the research problems described in Chapter ~\ref{cap3}, the Pluto programming framework.
In Section \ref{programmingModel} we present our programming model:
we show the entities of our model and the relationships between them.
We also describe the blocks architecture of the Pluto Programming Framework, which is shown in Section \ref{functionalBlocks}.
In Section \ref{functionalBlocks} we describe in details the functionality of the available blocks of the Pluto Graphical Editor, that are the basic elements that the programmer can connect to graphically build an application.
In Section \ref{toolchain} we describe in details the two components of the Pluto framework:
the Graphical Editor, that is used by the programmer to graphically build an application and the Main Application, that is used by the final user to specify the sensing tasks to be performed.
In Section \ref{navigationSystem} we describe the navigation system, that is the conjunction point between the Main Application and the drones team.
The last Section of the Chapter, the \ref{history}, describes all the steps performed to arrive to the final system, showing all the previously implemented solutions which, once refined, brought us to the development of the Pluto programming framework.
\\

Chapter~\ref{cap5} shows how the designed choices have been implemented technically, describing all the software and tools used for the development of Pluto programming framework.
In Section \ref{editor} we describe the GEF framework, which we used to implement the Pluto Graphical Editor.
In Section \ref{codeGeneration} we show the code generation process that creates a Java application from the graph built with the Pluto Graphical Editor.
In Section \ref{oomodel} we motivate the choice of an Object-Oriented programming model for the Pluto framework.
In Section \ref{runtimeMng} we describe the runtime features of Pluto:
the parallel architecture and the management of all the needed threads.
In Section \ref{interface} we describe the SWING tool, which we used to develop the Pluto Main Application.
Finally, in Section \ref{crazyflie} we describe the Crazyflie nano-quadcopter, which we used to perform the sensing tasks of our prototype applications.
\\

Chapter~\ref{cap6} starts with an analysis on the applicability of the Pluto framework.
In Section \ref{applicability} we describe four already existing applications and three case study, and we discuss on whether they can be developed or not with Pluto. 
In Section \ref{usability} we propose two exercises to real testers, in order to test "on the field" the effective usability of Pluto:
the first one deals with the Graphical Editor, the second one with the Main Application.
Then we propose a third exercise, in which we ask the users to directly use the API of the Crazyflie nano-quadcopter, shown in section \ref{crazyflie}, to make it move from a point A to a point B.
We also propose a survey to the users and then present the result in a graphical way, in order to have opinions on the framework and possibly to improve it with the suggestions of the testers.
In Section \ref{performance} we measure the software and hardware consumption metrics required by Pluto, in order to evaluate the effective impact of Pluto on an ordinary computing machine.
\\

Finally, Chapter~\ref{cap7} draws the conclusion and recaps the results obtained, also showing the possibilities for future works to extend our programming model.